{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a744f93d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 207\u001b[0m\n\u001b[0;32m    205\u001b[0m root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[0;32m    206\u001b[0m app \u001b[38;5;241m=\u001b[39m LeetCodeClassifierApp(root)\n\u001b[1;32m--> 207\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shfsd\\miniconda3\\envs\\myenv\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox\n",
    "import threading\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class LeetCodeClassifierApp:\n",
    "    def __init__(self, root, model_path=\"./leetcode-classifier-model\"):\n",
    "        self.root = root\n",
    "        self.root.title(\"LeetCode Problem Classifier\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "        self.root.minsize(600, 500)\n",
    "        \n",
    "        # Path to model\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        # Check for CUDA availability\n",
    "        self.cuda_available = torch.cuda.is_available()\n",
    "        self.device = \"cuda\" if self.cuda_available else \"cpu\"\n",
    "        \n",
    "        # Status variable\n",
    "        self.load_model_status = tk.StringVar()\n",
    "        self.load_model_status.set(f\"Status: Loading model on {'GPU (CUDA)' if self.cuda_available else 'CPU'}...\")\n",
    "        \n",
    "        # UI elements\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Load model in a separate thread\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        threading.Thread(target=self.load_model).start()\n",
    "        \n",
    "        # Categories list\n",
    "        self.categories = [\n",
    "            \"Array\", \"Dynamic Programming\", \"String\", \"Math\", \"Tree\", \n",
    "            \"Depth-first Search\", \"Greedy\", \"Hash Table\", \"Binary Search\", \n",
    "            \"Breadth-first Search\", \"Sort\", \"Two Pointers\", \"Backtracking\", \n",
    "            \"Stack\", \"Design\"\n",
    "        ]\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        # Main frame to contain everything\n",
    "        main_frame = tk.Frame(self.root)\n",
    "        main_frame.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Title\n",
    "        title_label = tk.Label(main_frame, text=\"LeetCode Problem Classifier\", font=(\"Arial\", 18, \"bold\"))\n",
    "        title_label.pack(pady=10)\n",
    "        \n",
    "        # GPU status indicator\n",
    "        gpu_status = \"GPU ENABLED\" if self.cuda_available else \"CPU MODE\"\n",
    "        gpu_color = \"#4CAF50\" if self.cuda_available else \"#FFA500\"\n",
    "        gpu_label = tk.Label(main_frame, text=gpu_status, font=(\"Arial\", 10, \"bold\"),\n",
    "                            fg=\"white\", bg=gpu_color, padx=10, pady=5)\n",
    "        gpu_label.pack(pady=5)\n",
    "        \n",
    "        # Instructions\n",
    "        instructions = tk.Label(main_frame, text=\"Enter a problem description and click 'Classify' to determine the problem type\")\n",
    "        instructions.pack(pady=5)\n",
    "        \n",
    "        # Status label\n",
    "        status_label = tk.Label(main_frame, textvariable=self.load_model_status)\n",
    "        status_label.pack(pady=5)\n",
    "        \n",
    "        # Text input area\n",
    "        input_label = tk.Label(main_frame, text=\"Problem Description:\")\n",
    "        input_label.pack(anchor='w', padx=10)\n",
    "        \n",
    "        self.text_input = scrolledtext.ScrolledText(main_frame, wrap=tk.WORD, height=15)\n",
    "        self.text_input.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Example buttons\n",
    "        examples_frame = tk.Frame(main_frame)\n",
    "        examples_frame.pack(fill='x', padx=10)\n",
    "        \n",
    "        examples_label = tk.Label(examples_frame, text=\"Examples:\")\n",
    "        examples_label.pack(anchor='w')\n",
    "        \n",
    "        examples_buttons_frame = tk.Frame(examples_frame)\n",
    "        examples_buttons_frame.pack(fill='x', pady=5)\n",
    "        \n",
    "        examples = {\n",
    "            \"Two Sum\": \"Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\",\n",
    "            \"Valid Parentheses\": \"Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\",\n",
    "            \"Merge Sorted Lists\": \"You are given the heads of two sorted linked lists list1 and list2. Merge the two lists into one sorted list.\"\n",
    "        }\n",
    "        \n",
    "        col = 0\n",
    "        for title, description in examples.items():\n",
    "            btn = tk.Button(examples_buttons_frame, text=title, \n",
    "                            command=lambda desc=description: self.set_example(desc))\n",
    "            btn.grid(row=0, column=col, padx=5)\n",
    "            col += 1\n",
    "        \n",
    "        # Result display\n",
    "        result_label = tk.Label(main_frame, text=\"Result:\", font=(\"Arial\", 12))\n",
    "        result_label.pack(anchor='w', padx=10, pady=(10, 0))\n",
    "        \n",
    "        self.result_display = tk.Label(main_frame, text=\"No classification yet\", font=(\"Arial\", 14), \n",
    "                                      bg=\"#f0f0f0\", relief=\"ridge\", height=2)\n",
    "        self.result_display.pack(fill='x', padx=10, pady=5)\n",
    "        \n",
    "        # Classify button\n",
    "        self.classify_button = tk.Button(main_frame, text=\"CLASSIFY PROBLEM\", command=self.classify_problem, \n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 14, \"bold\"), \n",
    "                                     height=2, relief=\"raised\", borderwidth=3)\n",
    "        self.classify_button.pack(fill='x', padx=50, pady=20)\n",
    "        \n",
    "        # Disable classify button until model is loaded\n",
    "        self.classify_button.config(state=tk.DISABLED)\n",
    "    \n",
    "    def load_model(self):\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "            \n",
    "            # Load model and move to GPU if available\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path, \n",
    "                torch_dtype=torch.float16 if self.cuda_available else torch.float32\n",
    "            )\n",
    "            \n",
    "            # Move model to GPU if available\n",
    "            if self.cuda_available:\n",
    "                self.model = self.model.to(\"cuda\")\n",
    "                \n",
    "            device_info = f\"GPU (CUDA)\" if self.cuda_available else \"CPU\"\n",
    "            self.load_model_status.set(f\"Status: Model loaded successfully on {device_info}!\")\n",
    "            self.classify_button.config(state=tk.NORMAL)\n",
    "        except Exception as e:\n",
    "            self.load_model_status.set(f\"Error loading model: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load model: {str(e)}\")\n",
    "    \n",
    "    def set_example(self, description):\n",
    "        self.text_input.delete(1.0, tk.END)\n",
    "        self.text_input.insert(tk.END, description)\n",
    "    \n",
    "    def classify_problem(self):\n",
    "        if not self.model or not self.tokenizer:\n",
    "            messagebox.showwarning(\"Warning\", \"Model is not loaded yet\")\n",
    "            return\n",
    "        \n",
    "        problem_description = self.text_input.get(1.0, tk.END).strip()\n",
    "        if not problem_description:\n",
    "            messagebox.showwarning(\"Warning\", \"Please enter a problem description\")\n",
    "            return\n",
    "        \n",
    "        self.classify_button.config(state=tk.DISABLED, text=\"Classifying...\")\n",
    "        self.load_model_status.set(\"Status: Classifying problem...\")\n",
    "        \n",
    "        # Run classification in a separate thread to avoid freezing the UI\n",
    "        threading.Thread(target=self.run_classification, args=(problem_description,)).start()\n",
    "    \n",
    "    def run_classification(self, problem_description):\n",
    "        try:\n",
    "            prompt = f\"\"\"Given the following programming problem, classify it into one of these categories:\n",
    "Array, Dynamic Programming, String, Math, Tree, Depth-first Search, Greedy, Hash Table, Binary Search, Breadth-first Search, Sort, Two Pointers, Backtracking, Stack, Design\n",
    "\n",
    "Problem description:\n",
    "{problem_description}\n",
    "\n",
    "The problem type is:\"\"\"\n",
    "            \n",
    "            # Create inputs and move to CUDA if available\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "            \n",
    "            if self.cuda_available:\n",
    "                # Move inputs to GPU\n",
    "                inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=10,\n",
    "                    temperature=0.1,\n",
    "                    num_return_sequences=1,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predicted_category = generated_text.split(\"The problem type is:\")[-1].strip()\n",
    "            \n",
    "            # Match to closest category\n",
    "            for category in self.categories:\n",
    "                if category.lower() in predicted_category.lower():\n",
    "                    predicted_category = category\n",
    "                    break\n",
    "            \n",
    "            # Update UI on the main thread\n",
    "            self.root.after(0, self.update_result, predicted_category)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.root.after(0, self.show_error, str(e))\n",
    "    \n",
    "    def update_result(self, result):\n",
    "        self.result_display.config(text=f\"Problem Type: {result}\")\n",
    "        self.classify_button.config(state=tk.NORMAL, text=\"CLASSIFY PROBLEM\")\n",
    "        self.load_model_status.set(\"Status: Ready\")\n",
    "    \n",
    "    def show_error(self, error_msg):\n",
    "        messagebox.showerror(\"Error\", f\"Classification failed: {error_msg}\")\n",
    "        self.classify_button.config(state=tk.NORMAL, text=\"CLASSIFY PROBLEM\")\n",
    "        self.load_model_status.set(\"Status: Ready\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = LeetCodeClassifierApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
